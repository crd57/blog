# 多层感知机
随着层数越多，所需的节点数目下降,但是随着层数的增多又会出现其他的问题：
1. 过拟合
解决办法： DropOut
2. 参数难以调试
尤其是梯度下降的参数使用Adagrad、Adam、Adadelta等自适应的方法可以降低调试参数的负担。
3. 梯度弥散
使用Sigmoid在反向传播中梯度值会逐渐减少，经过多层的传递后会呈指数级的剧烈减少，因此梯度值在传递到前面几层时就变得非常小了这种情况下，根据训练数据的反馈来更新神经网络的参数将会非常缓慢
使用ReLU激活函数
特点：
1. 单侧抑制性
2. 相对宽阔的兴奋边界
3. 稀疏激活性
输出层一般都还是Sigmoid函数，他符合概率输出分布




