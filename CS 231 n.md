# CS 231 n

## 损失函数

![](http://oymv8fxwf.bkt.clouddn.com/17-11-9/37482280.jpg)

### Hinge loss

$$
L_i  = \sum_{j \not= y_i}\max(0,1+s_j-s_{y_i})
$$

$$
L = \frac{1}{N}\sum L_i
$$



如果正确分类，则损失是0，否则损失就是$1+s_j-s_{y_i}$

当用很小的值初始化时，损失函数的值为$C-1$ 其中$C$为类别数，如果不为此值时应该是代码错了。

如果出现满足损失函数最小的情况下避免出现过拟合你需要正则化
$$
L = \sum_{j \not= y_i}\max(0,1+s_j-s_{y_i}) +\lambda R(w)
$$
正则化的目的就是减轻模型的复杂度，而不是去试图拟合数据

 系数W的意义就是在多大程度上对输出有影响。

### Softmax Loss

$$
P(Y = k|X=x_i )=\frac{e^{s_k}}{\sum_je^{s_j}} \qquad  	where \quad s=  f(x_i;W)  \\
L_i = -logP(Y=y_i|X = x_i)
$$

![2018-05-02 (1)](D:\OneDrive\图片\屏幕快照\2018-05-02 (1).png)

当用零来初始化权重时$L_i = log(C)$ 

## 优化器

在使用梯度下降时你并会使用数值梯度，而是解析梯度

数值梯度用来调试程序

通常使用随机梯度下降来更新梯度

### 随机梯度下降

在每一次迭代中，选取一小部分训练样本成为minibatch(小批量)，一般取2的n次幂。

可以视为对真实数值期望的一种蒙特卡洛估计



## 特征向量

方向梯度直方图

词袋